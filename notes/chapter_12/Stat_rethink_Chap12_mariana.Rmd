---
title: "Stat_rethink Chapter 12"
author: "Mariana CHiozza"
date: "8/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Monsters and Mixtures


## 12.1 OVER-DISPERSED COUNTS

When counts are more variable than a pure process (pure Gaussian)

The variance of a variable is called dispersion

Solution: Discover the omitted source of dispersion and include it in the model. There are two other strategies when no additional variables are available:

1) Continuous mixture models: A linear model is attached to a distribution of observations. Ex: beta-binomial and gamma-Poison (negative binomial)

2) Multilevels models: Estimate both, the residuals of each observation and the distribution of those residuals.


### 12.1.1 Beta-binomial

Each binomial count observation has its own probability of success. THere is a distribution of probabilities of success.

beta-distribution is a probability distribution for probabilities. It has two parameters: average probability (pbar) and theta.

```{r}
library(rethinking)
pbar <- 0.5
theta <- 5
curve( dbeta2(x,pbar,theta) , from=0 , to=1 ,
    xlab="probability" , ylab="Density" )

pbar2 <- 0.5
theta2 <- 2
curve( dbeta2(x,pbar2,theta2) , from=0 , to=1 ,
    xlab="probability" , ylab="Density" )

pbar3 <- 0.5
theta3 <- 1
curve( dbeta2(x,pbar3,theta3) , from=0 , to=1 ,
    xlab="probability" , ylab="Density" )
```



Bind the linear model to pbar, so that changes in predictor variables change the central tendency of the distribution.

```{r}
library(rethinking)
data(UCBadmit)
d <- UCBadmit
d$gid <- ifelse( d$applicant.gender=="male" , 1L , 2L )
dat <- list( A=d$admit , N=d$applications , gid=d$gid )
m12.1 <- ulam(
    alist(
        A ~ dbetabinom( N , pbar , theta ),
        logit(pbar) <- a[gid],
        a[gid] ~ dnorm( 0 , 1.5 ),
        transpars> theta <<- phi + 2.0,
        phi ~ dexp(1)
    ), data=dat , chains=4 )


post <- extract.samples( m12.1 )
post$da <- post$a[,1] - post$a[,2]
precis( post , depth=2 )

```

### 12.1.2 Gamma-Poison

Each Poison count observation has its own rate. It estimates the shape of a gamma distribution to describe the Poisson rates across cases.

Poisson distributions are very narrow. The variance muest equal the mean!!

Two parameters:

- mean (rate) = lambda

- dispersion (scale) of the rates across cases 

Treat the very influencial points because gamma-Poisson expects more variation around the mean rate.


### 12.1.3 Over-dispersion entropy and information criteria

Should not use WAIC and PSIS with these models.

Recall, the beta-binomial and gamma-Poisson models implies the same latent probability for all of the applicants from the same row in the data. We can not disaggregate the data. 


## 12.2 ZERO-INFLATED OUTCOMES

Incorporate processes to discriminate between zero outcomes which can come from the different processes. If total zeros are considered, the zeros will be inflated. EX: Zero manuscript done by monks in a day due to 1) drinking or 2) low rate of work. 

Zero-inflated Poissonlikelihood = dzipois

```{r}
prob_drink<-0.2
rate_work<-1
N<-365

set.seed(365)
drink<-rbinom(N, 1, prob_drink)

y<-(1-drink)*rpois(N, rate_work)

m12.3 <- ulam(
    alist(
        y ~ dzipois( p , lambda ),
        logit(p) <- ap,
        log(lambda) <- al,
        ap ~ dnorm( -1.5 , 1 ),
        al ~ dnorm( 1 , 0.5 )
    ) , data=list(y=y) , chains=4 )
precis( m12.3 )

```


```{r}
post <- extract.samples( m12.3 )
mean( inv_logit( post$ap ) ) # probability drink
mean( exp( post$al ) )       # rate finish manuscripts, when not drinking
```

## 12.3 ORDERED CATEGORICAL OUTCOMES

### Practice problems 12M1 and 12M2.

```{r}
employees <- 1:96
rate <- c('1', '2', '3', '4')
df <- data.frame(employees,rate)
df

df[c(1:12), 2] = "1"
df[c(13:48), 2] = "2"
df[c(49:55), 2] = "3"
df[c(56:96), 2] = "4"

df$rate <- as.numeric(as.factor(df$rate))

simplehist(df$rate , xlim=c(1,4) , xlab="rate")

# Discrete proportions
pr_k <- table(df$rate)/nrow(df)

# Cumulative proportions
cum_pr_k<-cumsum(pr_k)

#plot

plot(1:4, cum_pr_k, type="b", xlab="rate" ,
     ylab="cumulative proportion" , ylim=c(0,1) )


logit<-(function(x) log(x/(1-x)))
round(lco<-logit(cum_pr_k) , 2)

plot(1:4, lco, type="b", xlab="rate" ,
     ylab="log-cumulative odds" )

```

```{r}
m12M2<-ulam(
    alist(
        R ~ dordlogit( 0 , cutpoints ),
        cutpoints ~ dnorm( 0 , 1.5 )
    ) , data=list( R=df$rate ), chains=4 , cores=4 )
precis(m12M2, depth = 2)

round(inv_logit(coef(m12M2)) , 3)

```


### 12H1.

```{r}
library(rethinking)
data(Hurricanes)
d<-Hurricanes

dat <- list(
    D = d$deaths ,
    f = d$femininity )

# intercept only
m12H1 <- ulam(
    alist(
        D ~ dpois( lambda ),
        log(lambda) <- a,
        a ~ dnorm( 0 , 1 )
    ), data=dat , chains=4 , log_lik=TRUE )

precis(m12H1)


# Adding a predictor
m12.H1.1 <- ulam(
    alist(
        D ~ dpois( lambda ),
        log(lambda) <- a + b*f,
        a ~ dnorm( 0 , 1 ),
        b ~ dnorm( 0 , 1 )
    ), data=dat , chains=4 , log_lik=TRUE )

compare(m12H1, m12.H1.1, func = PSIS)


plot( d$femininity , d$deaths , xlab="femininity" , ylab="deaths" ,
    col=rangi2)



```

