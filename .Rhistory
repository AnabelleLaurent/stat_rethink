theta.old <- theta.new
}
theta.vec[i] <- theta.old
}
return(list(theta = theta.vec))
}
mm <- metrop(y, n = 100, start = 10, sigma = sd(y))
plot(mm$theta)
metrop <- function(x, n = 1e2, start = 1, sigma = 1){
theta.old <- start
theta.vec <- numeric(n)
for(i in 1:n){
theta.new <- theta.old + rnorm(1)
f.0 <- sum(dnorm(x, mean = theta.old, sd = sigma, log = TRUE))
f.1 <- sum(dnorm(x, mean = theta.new, sd = sigma, log = TRUE))
U <- runif(1)
R <- f.1 - f.0
## R = f.0 / f.1 is the same as log(f.0) - log(f.1) > log(U)
if(R > log(U)){
theta.old <- theta.new
}
theta.vec[i] <- theta.old
}
return(list(theta = theta.vec))
}
mm <- metrop(y, n = 100, start = 10, sigma = sd(y))
plot(mm$theta)
mm <- metrop(y, n = 1e3, start = 10, sigma = sd(y))
plot(mm$theta)
quantile(mm$theta, probs = c(0.025, 0.975))
confint(lm(y ~ 1))
metrop <- function(x, n = 1e2, start = 1, sigma = 1){
theta.old <- start
theta.vec <- numeric(n)
for(i in 1:n){
theta.new <- theta.old + rnorm(1)
f.0 <- sum(dnorm(x, mean = theta.old, sd = sigma, log = TRUE))
f.1 <- sum(dnorm(x, mean = theta.new, sd = sigma, log = TRUE))
U <- runif(1)
## As stated above f.0 is the log-likelihood, thus exp(f.0) would be the
## likelihood. If I take the log of R then
## log(R) = log(exp(f.1)) - log(exp(f.0))
## This simplifies to f.1 - f.0
R <- f.1 - f.0
if(R > log(U)){
theta.old <- theta.new
}
theta.vec[i] <- theta.old
}
return(list(theta = theta.vec))
}
set.seed(1234)
y <- rnorm(20, 15, 3)
## The mean is easy
mean(y)
## Confidence interval
confint(lm(y ~ 1))
mm <- metrop(y, n = 100, start = 10, sigma = sd(y))
## Plotting the trace
plot(mm$theta, xlab = "iteration", ylab = "theta", type = "l")
abline(h = mean(y), col = "red", lty = 2)
## Getting the distribution
mm2 <- metrop(y, n = 5e3, start = 7, sigma = sd(y))
## Computing the mean
mean(mm2$theta[500:5e3])
quantile(mm2$theta[500:5e3], probs = c(0.025, 0.975))
ry <- rnorm(1e4, mean = mean(y), sd = sd(y)/sqrt(length(y)))
plot(density(mm2$theta[500:5e3]), main = "", xlab = "theta", col = "red")
lines(density(ry), col = "blue")
mtext("blue = normal")
mtext("blue = normal", col = "blue")
?mtext
mtext("blue = normal", col = "blue", at = c(0, 1))
mtext("blue = normal", col = "blue", at = c(11, 0.6))
mtext("blue = normal", col = "blue", at = c(12, 0.6))
mtext("blue = normal", col = "blue", at = c(12, 0.5))
ry <- rnorm(1e4, mean = mean(y), sd = sd(y)/sqrt(length(y)))
plot(density(mm2$theta[500:5e3]), main = "", xlab = "theta", col = "red")
lines(density(ry), col = "blue")
mtext("blue = normal", col = "blue", at = c(12, 1))
mtext("red = metropolis", col = "red", at = c(15, 1))
ry <- rnorm(1e4, mean = mean(y), sd = sd(y)/sqrt(length(y)))
plot(density(mm2$theta[500:5e3]), main = "", xlab = "theta", col = "red")
lines(density(ry), col = "blue")
mtext("blue = normal", col = "blue", at = c(12.5, 1))
mtext("red = metropolis", col = "red", at = c(15, 1))
metrop <- function(x, n = 1e2, start = list(theta = 1, sigma = 1)){
theta.old <- start$theta
sigma.old <- start$sigma
theta.vec <- numeric(n)
sigma.vec <- numeric(n)
for(i in 1:n){
theta.new <- theta.old + rnorm(1)
sigma.new <- sigma.old + rnorm(1)
if(sigma.new < 0) sigma.new <- sigma.old
f.0 <- sum(dnorm(x, mean = theta.old, sd = sigma.old, log = TRUE))
f.1 <- sum(dnorm(x, mean = theta.new, sd = sigma.new, log = TRUE))
U <- runif(1)
## As stated above f.0 is the log-likelihood, thus exp(f.0) would be the
## likelihood. If I take the log of R then
## log(R) = log(exp(f.1)) - log(exp(f.0))
## This simplifies to f.1 - f.0
R <- f.1 - f.0
if(R > log(U)){
theta.old <- theta.new
sigma.old <- sigma.new
}
theta.vec[i] <- theta.old
sigma.vec[i] <- sigma.old
}
return(list(theta = theta.vec, sigma = sigma.vec))
}
set.seed(12345)
y <- rnorm(25, 20, 5)
mm <- metrop(y)
plot(mm$theta)
plot(mm$sigma)
mm <- metrop(y, n = 1e4)
plot(mm$theta)
plot(mm$sigma)
set.seed(12345)
y <- rnorm(25, 20, 5)
mm <- metrop(y, n = 50)
## Plotting the trace
plot(mm$theta, xlab = "iteration", ylab = "theta", type = "l")
abline(h = mean(y), col = "red", lty = 2)
mm <- metrop(y, n = 75)
plot(mm$theta, xlab = "iteration", ylab = "theta", type = "l")
abline(h = mean(y), col = "red", lty = 2)
mm <- metrop(y, n = 100)
plot(mm$theta, xlab = "iteration", ylab = "theta", type = "l")
abline(h = mean(y), col = "red", lty = 2)
plot(mm$sigma, xlab = "iteration", ylab = "sigma", type = "l")
abline(h = mean(y), col = "red", lty = 2)
## Trace plot for sigma
plot(mm$sigma, xlab = "iteration", ylab = "sigma", type = "l")
abline(h = sd(y), col = "red", lty = 2)
mm2 <- metrop(y, n = 15e3)
hist(mm2$theta[1e3:15e3], xlab = "theta", main = "Metropolis theta",
freq = FALSE)
hist(mm2$sigma[1e3:15e3], xlab = "sigma", main = "Metropolis sigma",
freq = FALSE)
?hist
hist(mm2$theta[1e3:15e3], xlab = "theta", main = "Metropolis theta",
freq = FALSE, breaks = 20)
hist(mm2$theta[1e3:15e3], xlab = "theta", main = "Metropolis theta",
freq = FALSE, breaks = 30)
hist(mm2$sigma[1e3:15e3], xlab = "sigma", main = "Metropolis sigma",
freq = FALSE, breaks = 30)
hist(mm2$theta[1e3:15e3], xlab = "theta", main = "Metropolis theta",
freq = FALSE, breaks = 30)
abline(v = mean(y))
hist(mm2$theta[1e3:15e3], xlab = "theta", main = "Metropolis theta",
freq = FALSE, breaks = 30)
abline(v = mean(y), col = "red", lwd = 3)
hist(mm2$sigma[1e3:15e3], xlab = "sigma", main = "Metropolis sigma",
freq = FALSE, breaks = 30)
abline(v = sd(y), col = "red", lwd = 3)
sd(y)
quantile(mm2$sigma, probs = c(0.025, 0.975))
daty <- data.frame(y = y)
bb <- brm(y ~ 1, data = daty)
bb
flm <- lm(y ~ 1)
flm.bt <- boot_lm(flm, sigma, R = 1e4)
flm.bt <- boot_lm(flm, f = sigma, R = 1e4)
?sigma
?boot_lm
boot_lm
ff <- function(x) sigma(x)
flm.bt <- boot_lm(flm, f = ff, R = 1e4)
flm <- lm(y ~ 1, data = daty)
flm.bt <- boot_lm(flm, f = ff, R = 1e4)
library(car)
confint(flm.bt)
flm.bt <- boot_lm(flm, f = ff, R = 2e4)
confint(flm.bt)
confint(flm.bt, type = "perc")
quantile(flm.bt$t, probs = c(0.025, 0.975))
hist(flm.bt)
flm.bt
summary(flm.bt)
flm.bt <- boot_lm(flm, R = 2e4)
hist(flm.bt)
flm.bt
summary(flm.bt)
library(MCMCpack)
help(package = "MCMCpack")
?MCMCmetrop1R
?MCMCmetrop1R
logitfun <- function(beta, y, X){
eta <- X %*% beta
p <- 1.0/(1.0+exp(-eta))
sum( y * log(p) + (1-y)*log(1-p) )
}
x1 <- rnorm(1000)
x2 <- rnorm(1000)
Xdata <- cbind(1,x1,x2)
p <- exp(.5 - x1 + x2)/(1+exp(.5 - x1 + x2))
yvector <- rbinom(1000, 1, p)
post.samp <- MCMCmetrop1R(logitfun, theta.init=c(0,0,0),
X=Xdata, y=yvector,
thin=1, mcmc=40000, burnin=500,
tune=c(1.5, 1.5, 1.5),
verbose=500, logfun=TRUE)
raftery.diag(post.samp)
plot(post.samp)
summary(post.samp)
library(nlraa)
?boot_lm
require(car)
data(barley, package = "nlraa")
## Fit a linear model (quadratic)
fit.lm <- lm(yield ~ NF + I(NF^2), data = barley)
## Bootstrap coefficients by default
fit.lm.bt <- boot_lm(fit.lm)
confint(fit.lm.bt, type = "perc")
confint(fit.lm)
fit.lm.bt <- boot_lm(fit.lm, R = 2e4)
confint(fit.lm.bt)
confint(fit.lm.bt, type = "perc")
confint(fit.lm)
library(rstanarm)
?stan_lm
fm.sa <- stan_lm(yield ~ NF + I(NF^2), data = barley)
fm.sa <- stan_lm(yield ~ NF + I(NF^2), data = barley, prior = R2())
fm.sa <- stan_lm(yield ~ NF + I(NF^2), data = barley, prior = R2(location = 1))
fm.sa <- stan_lm(yield ~ NF + I(NF^2), data = barley, prior = R2(location = 0.5))
fm.sa <- stan_lm(yield ~ NF + I(NF^2), data = barley, prior = R2(0.5))
fm.sa <- stan_lm(yield ~ NF + I(NF^2), data = barley, prior = R2(0.5, what = "mode"))
fm.sa <- stan_lm(yield ~ NF + I(NF^2), data = barley, prior = R2(0.5, what = "mean"))
fm.sa
confint(fm.sa)
posterior_interval(fm.sa)
fit.lm
summary(fit.lm)
posterior_interval(fm.sa)
confint(fit.lm.bt, type = "perc")
confint(fit.lm)
?simulate_lm
fit.lm.bt <- boot_lm(fit.lm, R = 2e4, psim = 4)
confint(fit.lm.bt, type = "perc")
xx <- seq(10, 20)
yy <- 5 + xx * 0.5 -0.5*xx^2
plot(xx, yy)
y <- rnorm(20, 15, 2)
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
LL <- dy(y, mean = 12, sigma = sd(y))
LL <- dy(y, mu = 12, sigma = sd(y))
LL
knitr::opts_chunk$set(echo = TRUE)
LL <- sapply(10:20, dy, sigma = sd(y))
?sapply
LL <- sapply(10:20, dy, sigma = sd(y), mu = i)
LL <- sapply(theta <- 10:20, dy, sigma = sd(y), y = y, mu = theta)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = theta[i], sigma = sd(y)))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = theta[i], sigma = sd(y)))
LL
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
LL
plot(thetas, LL)
plot(thetas, LL, type = "l")
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
mean(y)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
mean.y
se.y
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, hessian = TRUE)
m2LL.op <- optim(c(1,1), m2LL, hessian = TRUE, y = y)
m2LL.op
library(BioCro)
Opc4photo
solve(m2LL.op$hessian)
sqrt(solve(m2LL.op$hessian)[1,1])
se.y
sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
print(se.y, m2LL.se.mu)
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
print(se.y, m2LL.se.mu)
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
set.seed(1234)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, y = y, hessian = TRUE)
m2LL.op
## From the Hessian we can calculate the standard error for the mean
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
## This shows that we can obtain the precision for mu using maximum
## likelihood, but we need to calculate the Hessian
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
set.seed(12345)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, y = y, hessian = TRUE)
m2LL.op
## From the Hessian we can calculate the standard error for the mean
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
## This shows that we can obtain the precision for mu using maximum
## likelihood, but we need to calculate the Hessian
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
set.seed(123456)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, y = y, hessian = TRUE)
m2LL.op
## From the Hessian we can calculate the standard error for the mean
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
## This shows that we can obtain the precision for mu using maximum
## likelihood, but we need to calculate the Hessian
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
set.seed(1234567)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, y = y, hessian = TRUE)
m2LL.op
## From the Hessian we can calculate the standard error for the mean
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
## This shows that we can obtain the precision for mu using maximum
## likelihood, but we need to calculate the Hessian
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
set.seed(12345678)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
set.seed(2345678)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
set.seed(345678)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
set.seed(45678)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
set.seed(5678)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
set.seed(1)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
## This next function calculates the minus 2 log-likelihood
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, y = y, hessian = TRUE)
m2LL.op
## From the Hessian we can calculate the standard error for the mean
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
## This shows that we can obtain the precision for mu using maximum
## likelihood, but we need to calculate the Hessian
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
set.seed(12)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, y = y, hessian = TRUE)
m2LL.op
## From the Hessian we can calculate the standard error for the mean
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
## This shows that we can obtain the precision for mu using maximum
## likelihood, but we need to calculate the Hessian
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
set.seed(123)
y <- rnorm(20, 15, 2)
mean.y <- mean(y)
se.y <- sd(y)/sqrt(length(y))
dy <- function(y, mu, sigma) -2 * sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))
thetas <- seq(10, 20, by = 0.5)
LL <- sapply(1:length(thetas), function(i) dy(y = y, mu = thetas[i], sigma = sd(y)))
plot(thetas, LL, type = "l", xlab = "theta", ylab = "-2 log-likelihood")
m2LL <- function(cfs, y) -2 * sum(dnorm(y, mean = cfs[1], sd = cfs[2], log = TRUE))
m2LL.op <- optim(c(1,1), m2LL, y = y, hessian = TRUE)
m2LL.op
## From the Hessian we can calculate the standard error for the mean
m2LL.se.mu <- sqrt(solve(m2LL.op$hessian)[1,1] * m2LL.op$par[2])
## This shows that we can obtain the precision for mu using maximum
## likelihood, but we need to calculate the Hessian
print(list(se.y = se.y, m2LL.se.mu = m2LL.se.mu))
?boot_lm
require(car)
data(barley, package = "nlraa")
## Fit a linear model (quadratic)
fit.lm <- lm(yield ~ NF + I(NF^2), data = barley)
## Bootstrap coefficients by default
fit.lm.bt <- boot_lm(fit.lm)
confint(fit.lm)
fit.lm.bt <- boot_lm(fit.lm, psim = 4)
confint(fit.lm.bt)
y <- rnorm(20, 15, 3)
confint(lm(y ~ 1))
dat <- data.frame(y = y)
confint(boot_lm(lm(y ~ 1, data = dat)))
confint(boot_lm(lm(y ~ 1, data = dat), psim = 4))
confint(boot_lm(lm(y ~ 1, data = dat), resid.type = "n"))
confint(boot_lm(lm(y ~ 1, data = dat), resid.type = "normal"))
confint(lm(y ~ 1))
confint(boot_lm(lm(y ~ 1, data = dat), resid.type = "normal", psim = 4))
fit.sa <- rstanarm::stan_lm(y ~ 1, data = dat)
fit.sa <- rstanarm::stan_glm(y ~ 1, data = dat)
predictive_interval(fit.sa)
colMeans(predictive_interval(fit.sa))
confint(boot_lm(lm(y ~ 1, data = dat)))
confint(boot_lm(lm(y ~ 1, data = dat)), type = "perc")
confint(boot_lm(lm(y ~ 1, data = dat, psim = 3)), type = "perc")
library(brms)
fm.br <- brm(y ~ 1, data = dat)
predictive_interval(fm.br)
posterior_interval(fm.br)
posterior_epred(fm.br)
posterior_summary(posterior_epred(fm.br))
posterior_interval(fm.br)
posterior_interval(fm.br)
predictive_interval(fm.br)
fm0 <- lm(y ~ 1, data = dat)
fm0.bt <- boot_lm(fm0, psim = 2)
confint(fm0.bt)
fm0.sim <- simulate_lm(fm0, nsim = 1e3, psim = 3)
dim(fm0.sim)
quantile(c(fm0.sim), probs = c(0.025, 0.975))
fm0.sim <- simulate_lm(fm0, nsim = 1e4, psim = 3)
quantile(c(fm0.sim), probs = c(0.025, 0.975))
library(predintma)
pdi <- pred_int(dat$y)
pdi
?pred_int
pdi.bt <- pred_int(dat$y, method = "boot")
pdi.bt <- pred_int_boot(dat$y)
?pred_int_boot
pdi.bt <- pred_int(dat$y, method = "conformal")
pdi.bt
?pred_int
?pred_int_boot
?boot_tmeans
pred_int
library(predintma)
require(ggplot2)
data(soyrs)
## Simply calculate the trial means
tmns <- aggregate(lrr ~ Trial_ID, data = soyrs, FUN = mean)
## Bootstrapped stratified trial means
btm <- boot_tmeans(lrr ~ Trial_ID, data = soyrs, R = 2e3)
pdi.cf <- pred_int_conformal_df(formula = lrr ~ Trial_ID, x = soyrs)
btmd <- btm$dat
btm.q <- btm$pdi
ggplot() + xlab("lrr") +
geom_density(data = btmd, aes(x = ys)) +
geom_jitter(data = soyrs, aes(x = lrr, y = 2.5)) +
geom_jitter(data = tmns, aes(x = lrr, y = 5), color = "blue", size = 1.2) +
geom_point(aes(x = pdi.cf[1], y = -1), color = "orange", size = 1.2) +
geom_errorbarh(mapping = aes(xmin = pdi.cf[2], xmax = pdi.cf[3],
y = -1), color = "orange", size = 1.2) +
geom_point(aes(x = btm.q[1], y = -2), color = "red", size = 1.2) +
geom_errorbarh(aes(xmin = btm.q[2], xmax = btm.q[3], y = -2),
color = "red", size = 1.2)
